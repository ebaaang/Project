{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Exploration 1] 인공지능하고 가위바위보하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 위와 같은 헤더를 가졌지만 실제로 가위바위보를 하는건 아니다.    \n",
    "#### 사진을 보고 [가위] [바위] [보] 를 맞추는 인공지능 분류기(classifier)를 만들어보겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_* 코드가 어떻게 이루어졌는데 하나하나 분석하지는 않았다. 이번 단계에서는 이미 짜져있는 코드를 활용해서 분류기를 만든다_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) 데이터셋 사진 촬영 및 디렉토리 설정하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저, 테스트셋으로 사용할 가위, 바위, 보의 사진 각 100장을 준비한다. 사진은 구글의 teachable machine을 활용하여 **순식간에** 100장을 촬영할 수 있다.   \n",
    "[Teachable Machine](https://teachablemachine.withgoogle.com/)   \n",
    "   \n",
    "사진이 준비 되었다면, 가위, 바위 보 각각의 디렉토리를 만들어 사진을 준비시킨다 (100장 씩!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__Tip:__ ```mkdir -p``` __를 사용하면 중간 단계의 디렉토리를 자동적으로 생성해주며 하위 디렉토리까지 생성할 수 있다!__*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mkdir -p ~/aiffel/가위바위보/가위```   \n",
    "```mkdir -p ~/aiffel/가위바위보/바위```   \n",
    "```mkdir -p ~/aiffel/가위바위보/보```   \n",
    "\n",
    "#(mkdir -p가 쥬피터에서는 실행이 안되어 터미널에서 실행하였음.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 이미지 리사이징"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음 스텝으로는 **이미지 리사이징**이 있다.   \n",
    "teachable machine에서 촬영한 사진은 224x224 픽셀 사이즈로, 분류기를 만들기에 불필요하게 크니   \n",
    "속도 향상을 위해서 28x28사이즈로 줄여보겠다.\n",
    "\n",
    "아래의 PIL 라이브러리 패키지를 다운받고 설치해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /home/aiffel/anaconda3/lib/python3.7/site-packages (7.0.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow   \n",
    "\n",
    "from PIL import Image\n",
    "import os, glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이후 아래 코드를 실행하여 이미지 크기를 줄여준다 --> 28x28 사이즈로!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/가위바위보/가위\n",
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/가위바위보/바위\n",
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/가위바위보/보\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "#가위, 바위, 보 모두 리사이징을 해준다.\n",
    "#image_dir_path에서 사진이 들어있는 올바른 위치를 설정해준다.\n",
    "\n",
    "#1. 가위\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/가위바위보/가위\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "    \n",
    "    \n",
    "#2. 바위\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/가위바위보/바위\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "    \n",
    "#3. 보\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/가위바위보/보\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가위, 바위, 보 사진이 각각 28 * 28 사이즈로 리사이징 되어 저장되었다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 3599 입니다.\n",
      "x_train shape: (3600, 28, 28, 3)\n",
      "y_train shape: (3600,)\n"
     ]
    }
   ],
   "source": [
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=3600   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/가위/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/바위/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/보/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/가위바위보\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 함수를 통해 x_train와 y_train dataset의 값을 입력해 주었다.   \n",
    "가위, 바위, 보 각각 1200장으로 총 3600장의 사진이 들어갔다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) 딥러닝 네트워크 설계하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저, **텐서플로우(tensorflow)**와 **케라스(Keras)**를 **import**하여 활성화(?) 시켜준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__) #tenserflow가 제대로 import되었는지 확인하기 위해 버전을 출력해본다...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서는 **tensorflow** 케라스의 **Sequential Model**을 사용한다. 아래 코드를 입력하여 **Sequential API**를 사용할 수 있다.   \n",
    "_(설명에 따르면, Sequential API를 통해 **딥러닝 레이어를 쉽게** 사용할 수 있다고 한다. 하지만 개발의 자유도가 떨어진다고 한다.)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래와 같이 ```model.summar()``` 메서드를 통해 네트워크 모델을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 30,762\n",
      "Trainable params: 30,762\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 3599 입니다.\n",
      "x_train shape: (3600, 28, 28, 3)\n",
      "y_train shape: (3600,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/가위바위보\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```.shape```을 통해 학습된 데이터 내용을 확인할 수 있다.   \n",
    "3600장의 사진은 28x28의 픽셀을 가지고 있고, 3채널의 사진임을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 3599 입니다.\n",
      "Before Reshape - x_train_norm shape: (3600, 28, 28, 3)\n",
      "Before Reshape - x_test_norm shape: (3600, 28, 28, 3)\n",
      "After Reshape - x_train_reshaped shape: (3600, 28, 28, 3)\n",
      "After Reshape - x_test_reshaped shape: (3600, 28, 28, 3)\n"
     ]
    }
   ],
   "source": [
    "(x_test, y_test)=load_data(image_dir_path)\n",
    "x_test_norm = x_test / 255.0\n",
    "\n",
    "print(\"Before Reshape - x_train_norm shape: {}\".format(x_train_norm.shape))\n",
    "print(\"Before Reshape - x_test_norm shape: {}\".format(x_test_norm.shape))\n",
    "\n",
    "x_train_reshaped=x_train_norm.reshape(-1,  28, 28, 3)\n",
    "x_test_reshaped=x_test_norm.reshape( -1, 28, 28, 3)\n",
    "\n",
    "print(\"After Reshape - x_train_reshaped shape: {}\".format(x_train_reshaped.shape))\n",
    "print(\"After Reshape - x_test_reshaped shape: {}\".format(x_test_reshaped.shape))\n",
    "\n",
    "#혹시 모를때!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 부분은 빼도 되지 않나 싶다. 왜냐아면 이미 3채널로 나와있기 때문에."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) 딥러닝 네트워크 학습시키기 !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1378 - accuracy: 0.9608\n",
      "Epoch 2/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1084 - accuracy: 0.9728\n",
      "Epoch 3/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1050 - accuracy: 0.9686\n",
      "Epoch 4/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.0757 - accuracy: 0.9797\n",
      "Epoch 5/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.0605 - accuracy: 0.9839\n",
      "Epoch 6/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.0533 - accuracy: 0.9858\n",
      "Epoch 7/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.0476 - accuracy: 0.9878\n",
      "Epoch 8/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.0429 - accuracy: 0.9892\n",
      "Epoch 9/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.0376 - accuracy: 0.9897\n",
      "Epoch 10/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 0.0312 - accuracy: 0.9925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcf8dde94d0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_reshaped, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습을 시키니 꽤 높은 정확도를 보인다 ㅎㅎ~!   \n",
    "프로젝트 제출을 준비하는 과정에서 여기서 알수 없는 오류로 막혔었다.   \n",
    "슬랙에 질문을 하니 퍼실님들께서 구글링을 통해 찾을 수 있도록 유도를 해주셨고, 찾아보니 위에 layer에 input이 1이 되어 있어 오류가 있었다.   \n",
    "아래는 스스로 해답을 찾는 과정에서 공부한 내용이다. 결론적으론 이것들이 문제는 아니었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```complie()``` 메서드는 모델 학습 과정을 설명해준다. 즉, 모델을 빌드하고 실행하기 전에 컴파일 하는 훈련준비단계라고 생각하면 된다.   \n",
    "\n",
    "\n",
    "* loss : 최적화 과정에서 최소화될 손실함수를 설정하는 것으로, MSE(평균 제곱 오차)와 binary_crossentropy가 자주 사용된다\n",
    "\n",
    "* optimizer : 훈련 과정을 설정하는 것으로, Adam, SGD 등이 있다\n",
    "\n",
    "* metrics : 훈련을 모니터링하기 위해 사용한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```fit()``` 메서드는 주어진 epoch 수 만큼 모델을 학습시킨다.\n",
    "* batch_size 는 한 번에 사용해야 하는 트레이닝 데이터의 크기를 지정하는 것\n",
    "* vervise 는 학습 진행 상황에 대한 출력 여부를 지정하는 것 (0(silent), 1(progress bar), 2(one line per epoch))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(위 내용들은 블로그 https://blog.naver.com/handuelly/221822938182 를 참고하였음)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) 얼마나 잘 만들었는지 확인하기!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_test)의 이미지 개수는 300 입니다.\n"
     ]
    }
   ],
   "source": [
    "def load_test_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=300  \n",
    "    img_size=28\n",
    "    color=3\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img   \n",
    "        labels[idx]=0  \n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img\n",
    "        labels[idx]=1 \n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img \n",
    "        labels[idx]=2  \n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_test)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/RCP\"\n",
    "(x_test, y_test)=load_test_data(image_dir_path)\n",
    "x_test_norm = x_test/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 ```load_test_data```함수를 통해 테스트 데이터셋을 가져올 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (6)두근두근 테스트 정확도 확인하기!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 0s - loss: 103.4845 - accuracy: 0.7897\n",
      "test_loss: 103.48452758789062 \n",
      "test_accuracy: 0.789722204208374\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**78퍼센트**라는 높은 정확도를 보인다!   \n",
    "딱히 하이퍼파라미터를 바꿀 필요가 없어졌다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 회고:   \n",
    "1. 이번 프로젝트에서 어려웠던 점,   \n",
    "처음 하는 Exploration project이다보니, 이제 처음 프로그래밍을 배우는 나한테는 모든 내용이 어렵고 벅찼다.   \n",
    "X와 Y가 각각 무엇을 의미하는이 이해하는데 조차 한참이 걸렸다.   \n",
    "그리고 짜여진 코드들을 하나하나 해석해야한다는 데에 부담감을 느꼈다.   \n",
    "차차 배울 것이고, 공부할 것이고, 익숙해지겠지만, 전반적으로 난이도가 너무 높다고 느껴졌다.   \n",
    "\n",
    "   \n",
    "2. 프로젝트를 진행하면서 알아낸 점 혹은 아직 모호한 점.   \n",
    "매 프로젝트마다 새로운걸 많이 배운다. 그 과정에서 스스로 찾아보고 공부해야할게 많다.   \n",
    "모호한 점은, 아직 코드를 전체적으로 이해하지 못하고 복사/붙여넣기만 했다는 점이 아쉽다.   \n",
    "나중에 여력이 생기면 오늘 제출하는 프로젝트 파일을 보고 꼭 이해해보겠다.   \n",
    "\n",
    "\n",
    "3. 루브릭 평가 지표를 맞추기 위해 시도한 것들.   \n",
    "처음에 300장의 데이터셋을 가지고 테스트를 했을 때에는 34%정도의 정확도가 나왔다.   \n",
    "이후 2100장을 가지고 재시도를 했는데 50퍼센트 조금 넘었던 것 같다.   \n",
    "다른 사람들에게 물어보니 3000장 이상을 테스트하면 좋은 결과가 나온다길래 3600장을 넣었더니 높은 정확도가 나왔다.   \n",
    "파라미터들을 조금 바꿔볼 수도 있었는데 일단 데이터를 많이 학습시켜야겠다는 생각에 파라미터를 바꿔보지는 못했다.   \n",
    "   \n",
    "   \n",
    "4. 만약에 루브릭 평가 관련 지표를 달성 하지 못했을 때, 이유에 관한 추정.   \n",
    "파라미터와 학습 데이터가 좋지 못한 이유가 있을것 같다.   \n",
    "다행이도 나의 경우에는, 파라미터를 바꿔보기 전에 충분한 양의 데이터셋을 넣었더니 높은 정확도가 나왔다.  \n",
    "   \n",
    "   \n",
    "5. 자기 다짐   \n",
    "Aiffel 과정을 시작한지 2주 정도 되었는데 아직도 부족함을 많이 느낀다.   \n",
    "기본이 너무 없다보니 따라가는데 속도가 느리고 시간이 많이 걸린다.   \n",
    "구정을 기준으로 파이썬이라던지, 수학적인 부분에 기본기를 탄탄히 다질 수 있도록 시간투자를 많이 해야겠다.   \n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
