{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration 11 - 뉴스기사 요약하기 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번 프로젝트는 자연어 프로젝트 중, seq2seq 모델의 어텐션(Attention) 메커니즘을 사용하여 문장을 요약하는 프로젝트이다.   \n",
    "seq2seq 모델은 LSTM을 기반으로 한 모델로 인코더 부분과 디코더 부분으로 나누어 입력(인풋)을 인코더 부분에 넣고 LSTM이 학습하는 과정을 거친 후 이를 컨텍스트 벡터(context vector)형태로 변환한다. 그 다음으로 변환된 context vector을 디코더 부분에 넣어 예측할 문장을 생성하는 것이다.   \n",
    "   \n",
    "기본적인 개념에 대한 설명이었고, 실제로 위 모델을 사용하여 본문에서 중요한 단어를 LSTM 어텐션 메커니즘을 사용하여 학습한 후 얼만큼의 요약문을 만들어낼 수 있는지 확인해보겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 필요한 모듈 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/aiffel-\n",
      "[nltk_data]     dj58/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1. 데이터 준비하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\", filename=\"news_summary_more.csv\")\n",
    "data = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "뉴스요약에 사용될 데이터를 준비한다.   \n",
    "데이터는 위 코드를 통해 다운받을 수 있으며, data라는 변수에 pandas를 사용하여 불러온 후 Step 2에서 전처리를 진행하겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98401\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전체 데이터는 98401개를 가지고 있다.   \n",
    "데이터 형태를 살펴보면, headlines와 text부분으로 나뉘는데, text는 뉴스의 본문 내용이며 headlines는 뉴스의 제목이다.   \n",
    "headlines는 앞으로 학습할 모델에서 lable로 지정되는데 정확한 요약문은 아니더라도 본문에 내용을 충분히 반영하고 있다고 생각한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upGrad learner switches to career in ML &amp; Al w...</td>\n",
       "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delhi techie wins free food from Swiggy for on...</td>\n",
       "      <td>Kunal Shah's credit card bill payment platform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Zealand end Rohit Sharma-led India's 12-ma...</td>\n",
       "      <td>New Zealand defeated India by 8 wickets in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aegon life iTerm insurance plan helps customer...</td>\n",
       "      <td>With Aegon Life iTerm Insurance plan, customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Have known Hirani for yrs, what if MeToo claim...</td>\n",
       "      <td>Speaking about the sexual harassment allegatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rahat Fateh Ali Khan denies getting notice for...</td>\n",
       "      <td>Pakistani singer Rahat Fateh Ali Khan has deni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>India get all out for 92, their lowest ODI tot...</td>\n",
       "      <td>India recorded their lowest ODI total in New Z...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Govt directs Alok Verma to join work 1 day bef...</td>\n",
       "      <td>Weeks after ex-CBI Director Alok Verma told th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Called PM Modi 'sir' 10 times to satisfy his e...</td>\n",
       "      <td>Andhra Pradesh CM N Chandrababu Naidu has said...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cong wins Ramgarh bypoll in Rajasthan, takes t...</td>\n",
       "      <td>Congress candidate Shafia Zubair won the Ramga...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  upGrad learner switches to career in ML & Al w...   \n",
       "1  Delhi techie wins free food from Swiggy for on...   \n",
       "2  New Zealand end Rohit Sharma-led India's 12-ma...   \n",
       "3  Aegon life iTerm insurance plan helps customer...   \n",
       "4  Have known Hirani for yrs, what if MeToo claim...   \n",
       "5  Rahat Fateh Ali Khan denies getting notice for...   \n",
       "6  India get all out for 92, their lowest ODI tot...   \n",
       "7  Govt directs Alok Verma to join work 1 day bef...   \n",
       "8  Called PM Modi 'sir' 10 times to satisfy his e...   \n",
       "9  Cong wins Ramgarh bypoll in Rajasthan, takes t...   \n",
       "\n",
       "                                                text  \n",
       "0  Saurav Kant, an alumnus of upGrad and IIIT-B's...  \n",
       "1  Kunal Shah's credit card bill payment platform...  \n",
       "2  New Zealand defeated India by 8 wickets in the...  \n",
       "3  With Aegon Life iTerm Insurance plan, customer...  \n",
       "4  Speaking about the sexual harassment allegatio...  \n",
       "5  Pakistani singer Rahat Fateh Ali Khan has deni...  \n",
       "6  India recorded their lowest ODI total in New Z...  \n",
       "7  Weeks after ex-CBI Director Alok Verma told th...  \n",
       "8  Andhra Pradesh CM N Chandrababu Naidu has said...  \n",
       "9  Congress candidate Shafia Zubair won the Ramga...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2. 데이터 전처리하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 중복 샘플과 NULL 값이 존재하는 샘플 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 열에서 중복을 배제한 유일한 샘플의 수 : 98360\n",
      "Summary 열에서 중복을 배제한 유일한 샘플의 수 : 98280\n"
     ]
    }
   ],
   "source": [
    "print('Text 열에서 중복을 배제한 유일한 샘플의 수 :', data['text'].nunique())\n",
    "print('Summary 열에서 중복을 배제한 유일한 샘플의 수 :', data['headlines'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nunique`를 사용하여 중복되지 않은 값을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 98360\n"
     ]
    }
   ],
   "source": [
    "data.drop_duplicates(subset = ['text'], inplace = True)\n",
    "print('전체 샘플수 :',(len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "중복된 값들을 `drop_duplicates` 메서드를 사용하여 날려준다.   \n",
    "하지만 NULL로 중복되어있는 한개의 값이 남아있으므로 확인 후 drop 해주도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headlines    0\n",
      "text         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NULL값은 없는걸로 확인된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텍스트 정규화와 불용어 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
